lad_fit <- lad(data[,1] ~ poly(time, best_lad_degree))
plot(time, data[,1], col="blue", main="Fitted vs Actual",
ylab="Store Sales", xlab="Time")
fitted_values <- predict(lad_fit, newx=poly(time, best_lad_degree))
lines(fitted_values, col="red")
legend(x="bottomright", legend=c("Actual", "Fitted"), col=c("blue", "red"), pch=c(1,NA),lwd=c(NA,1))
par(mfrow=c(1,2))
residuals <- data[,1] - fitted_values
plot(time, residuals, main="Residuals vs Time")
acf(residuals)
lambda <- 10^(-4)
robust_ridge_loss <- function(beta, X, y) {
residuals <- y - X %*% beta
lad_loss <- mean(abs(residuals))
penalty <- lambda * sum(beta[-1]^2)
return (lad_loss + penalty)
}
apse_values <- c()
for (p in degrees) {
X_train <- as.matrix(poly(training_time, p))
X_test <- as.matrix(poly(test_time, p))
initial_beta <- rep(1, ncol(X_train) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X_train),
y=training_data)
beta <- fit$par
predictions <- cbind(1, X_test) %*% beta
squared_error <- (predictions - test_data)^2
APSE <- mean(squared_error)
apse_values <- c(apse_values, APSE)
}
plot(degrees, apse_values)
optimal_degree <- degrees[which.min(apse_values)]
print(paste0("The optimal degree is ", optimal_degree))
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright", legend=c("Test Data", "Training Data"), col=c("blue", "red"), pch=1)
fitted_values1 <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values2 <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values3 <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values4 <- cbind(1, X) %*% beta
lines(opt_fit, col="darkgreen", lwd=1)
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright", legend=c("Test Data", "Training Data"), col=c("blue", "red"), pch=1)
fitted_values1 <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values2 <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values3 <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values4 <- cbind(1, X) %*% beta
lines(fitted_values1, col="darkgreen", lwd=1)
lines(fitted_values2, col="darkorange", lwd=1)
lines(fitted_values3, col="purple", lwd=1)
lines(fitted_values4, col="yellow", lwd=1)
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright",
legend=c("Test Data", "Training Data", "Elastic Net",
"Least Squares", "Least Absolute Error", "Robust Ridge"),
col=c("blue", "red","darkgreen", "darkorange","purple","yellow"),
pch=c(1, 1, NA, NA, NA, NA),
lwd=c(NA,NA,1,1,1,1))
fitted_values1 <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values2 <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values3 <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values4 <- cbind(1, X) %*% beta
lines(fitted_values1, col="darkgreen", lwd=1)
lines(fitted_values2, col="darkorange", lwd=1)
lines(fitted_values3, col="purple", lwd=1)
lines(fitted_values4, col="yellow", lwd=1)
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright",
legend=c("Test Data", "Training Data", "Elastic Net",
"Least Squares", "Least Absolute Error", "Robust Ridge"),
col=c("blue", "red","darkgreen", "darkorange","purple","green"),
pch=c(1, 1, NA, NA, NA, NA),
lwd=c(NA,NA,1,1,1,1))
fitted_values1 <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values2 <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values3 <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values4 <- cbind(1, X) %*% beta
lines(fitted_values1, col="darkgreen", lwd=1)
lines(fitted_values2, col="darkorange", lwd=1)
lines(fitted_values3, col="purple", lwd=1)
lines(fitted_values4, col="green", lwd=1)
set.seed(123)
set.seed(123)
data <- read.csv("StoreSales.csv")
Test.indx <- sort(c(68, 167, 129, 162, 43, 14, 187, 51, 85, 21, 106,
182, 74, 7, 73, 79, 37, 105, 110, 165))
time <- 1:nrow(data)
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright", legend=c("Test Data", "Training Data"), col=c("blue", "red"), pch=1)
acf(data)
par(mfrow=c(2,2))
plot(lm(data[,1] ~ time))
library(glmnet)
degrees <- 2:15
Log.Lambda.Seq = c(c(-15, -10, -5, -2, -1, -0.5), seq(0, 10,
by = 0.1))
Lambda.Seq = exp(Log.Lambda.Seq)
alphas <- c(0, 0.5, 1)
training_data <- data[-Test.indx,]
training_time <- time[-Test.indx]
test_data <- data[Test.indx,]
test_time <- time[Test.indx]
optimal_fit <- list()
for (a in alphas) {
apse_values <- c()
for (i in seq_along(degrees)) {
p <- degrees[i]
X <- poly(training_time, p)
CV <- cv.glmnet(as.matrix(X), training_data,
alpha=a,standardize=TRUE,intercept=TRUE,
lambda=Lambda.Seq)
lambda <- CV$lambda.min
X_test <- poly(test_time, p)
predictions <- predict(CV, newx=as.matrix(X_test), s="lambda.min")
squared_errors <- (predictions - test_data)^2
APSE <- mean(squared_errors)
apse_values <- c(apse_values, APSE)
}
par(mfrow=c(1,2))
plot(degrees, apse_values, main=paste("APSE vs Degree, Alpha = ", a))
deg <- degrees[which.min(apse_values)]
plot(training_time, training_data,
main="Fitted Elastic Net Regression Model on Training Data")
X <- poly(training_time, deg)
CV <- cv.glmnet(as.matrix(X), training_data,
alpha=a,standardize=TRUE,intercept=TRUE,
lambda=Lambda.Seq)
fitted_values <- predict(CV, newx=as.matrix(X),s="lambda.min")
lines(fitted_values, col="red", lwd=2)
optimal_fit[[length(optimal_fit) + 1]] <- list(model = CV, degree = deg)
}
apse_values <- c()
for (i in seq_along(optimal_fit)) {
fit <- optimal_fit[[i]]$model
deg <- optimal_fit[[i]]$degree
predictions <- predict(fit, newx=as.matrix(poly(test_time, deg)), s="lambda.min")
squared_error <- (predictions - test_data)^2
APSE <- mean(squared_error)
apse_values <- c(apse_values, APSE)
print(paste0("Alpha = ", alphas[i], ", Degree = ", deg, ", APSE = ", APSE))
}
opt_idx <- which.min(apse_values)
print(paste0("The best model is Alpha = ", alphas[opt_idx], ", Degree = ", deg))
opt_fit <- optimal_fit[[opt_idx]]$model
opt_degree <- optimal_fit[[opt_idx]]$degree
plot(time, data[,1], col="blue", main="Fitted vs Actual",
ylab="Store Sales", xlab="Time")
fitted_values <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
lines(fitted_values, col="red")
legend(x="bottomright", legend=c("Actual", "Fitted"), col=c("blue", "red"), pch=c(1,NA),lwd=c(NA,1))
par(mfrow=c(1,2))
residuals <- data[,1] - fitted_values
plot(time, residuals, main="Residuals vs Time")
acf(residuals)
apse_values <- c()
for (i in seq_along(degrees)) {
p <- degrees[i]
fit <- lm(training_data ~ poly(training_time, p))
predictions <- predict(fit, newx=poly(test_time, p))
squared_error <- (predictions - test_data)^2
APSE <- mean(squared_error)
apse_values <- c(apse_values, APSE)
}
plot(degrees, apse_values)
best_ols_idx <- which.min(apse_values)
best_ols_degree <- degrees[best_ols_idx]
print(paste0("The best model has degree ", best_ols_degree))
ols_fit <- lm(data[,1] ~ poly(time, best_ols_degree))
plot(time, data[,1], col="blue", main="Fitted vs Actual",
ylab="Store Sales", xlab="Time")
fitted_values <- predict(ols_fit, newx=poly(time, best_ols_degree))
lines(fitted_values, col="red")
legend(x="bottomright", legend=c("Actual", "Fitted"), col=c("blue", "red"), pch=c(1,NA),lwd=c(NA,1))
par(mfrow=c(1,2))
residuals <- data[,1] - fitted_values
plot(time, residuals, main="Residuals vs Time")
acf(residuals)
library(L1pack)
apae_values <- c()
for (i in seq_along(degrees)) {
p <- degrees[i]
fit <- lad(training_data ~ poly(training_time, p))
predictions <- predict(fit, newx=poly(test_time, p))
absolute_error <- abs(predictions - test_data)
APAE <- mean(absolute_error)
apae_values <- c(apae_values, APAE)
}
plot(degrees, apae_values)
best_lad_idx <- which.min(apae_values)
best_lad_degree <- degrees[best_lad_idx]
print(paste0("The best model has degree ", best_lad_degree))
lad_fit <- lad(data[,1] ~ poly(time, best_lad_degree))
plot(time, data[,1], col="blue", main="Fitted vs Actual",
ylab="Store Sales", xlab="Time")
fitted_values <- predict(lad_fit, newx=poly(time, best_lad_degree))
lines(fitted_values, col="red")
legend(x="bottomright", legend=c("Actual", "Fitted"), col=c("blue", "red"), pch=c(1,NA),lwd=c(NA,1))
par(mfrow=c(1,2))
residuals <- data[,1] - fitted_values
plot(time, residuals, main="Residuals vs Time")
acf(residuals)
lambda <- 10^(-4)
robust_ridge_loss <- function(beta, X, y) {
residuals <- y - X %*% beta
lad_loss <- mean(abs(residuals))
penalty <- lambda * sum(beta[-1]^2)
return (lad_loss + penalty)
}
apse_values <- c()
for (p in degrees) {
X_train <- as.matrix(poly(training_time, p))
X_test <- as.matrix(poly(test_time, p))
initial_beta <- rep(1, ncol(X_train) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X_train),
y=training_data)
beta <- fit$par
predictions <- cbind(1, X_test) %*% beta
squared_error <- (predictions - test_data)^2
APSE <- mean(squared_error)
apse_values <- c(apse_values, APSE)
}
plot(degrees, apse_values)
optimal_degree <- degrees[which.min(apse_values)]
print(paste0("The optimal degree is ", optimal_degree))
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright",
legend=c("Test Data", "Training Data", "Elastic Net",
"Least Squares", "Least Absolute Error", "Robust Ridge"),
col=c("blue", "red","darkgreen", "darkorange","purple","brown"),
pch=c(1, 1, NA, NA, NA, NA),
lwd=c(NA,NA,1,1,1,1))
fitted_values1 <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values2 <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values3 <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values4 <- cbind(1, X) %*% beta
lines(fitted_values1, col="darkgreen", lwd=2)
lines(fitted_values2, col="darkorange", lwd=2)
lines(fitted_values3, col="purple", lwd=2)
lines(fitted_values4, col="brown", lwd=2)
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright",
legend=c("Test Data", "Training Data", "Elastic Net",
"Least Squares", "Least Absolute Error", "Robust Ridge"),
col=c("blue", "red","darkgreen", "darkorange","purple","brown"),
pch=c(1, 1, NA, NA, NA, NA),
lwd=c(NA,NA,1,1,1,1))
fitted_values <- c()
colors <- c("darkgreen","darkorange","purple","brown")
fitted_values1 <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values2 <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values3 <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values4 <- cbind(1, X) %*% beta
lines(fitted_values1, col="darkgreen", lwd=2)
lines(fitted_values2, col="darkorange", lwd=2)
lines(fitted_values3, col="purple", lwd=2)
lines(fitted_values4, col="brown", lwd=2)
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright",
legend=c("Test Data", "Training Data", "Elastic Net",
"Least Squares", "Least Absolute Error", "Robust Ridge"),
col=c("blue", "red","darkgreen", "darkorange","purple","brown"),
pch=c(1, 1, NA, NA, NA, NA),
lwd=c(NA,NA,1,1,1,1))
fitted_values <- c()
colors <- c("darkgreen","darkorange","purple","brown")
fitted_values[1] <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values[2] <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values[3] <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values[4] <- cbind(1, X) %*% beta
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[i]
lines(predictions, col=colors[i])
}
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright",
legend=c("Test Data", "Training Data", "Elastic Net",
"Least Squares", "Least Absolute Error", "Robust Ridge"),
col=c("blue", "red","darkgreen", "darkorange","purple","brown"),
pch=c(1, 1, NA, NA, NA, NA),
lwd=c(NA,NA,1,1,1,1))
fitted_values <- list()
colors <- c("darkgreen","darkorange","purple","brown")
fitted_values[[1]] <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values[[2]] <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values[[3]] <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values[4] <- cbind(1, X) %*% beta
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[i]
lines(predictions, col=colors[i])
}
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright",
legend=c("Test Data", "Training Data", "Elastic Net",
"Least Squares", "Least Absolute Error", "Robust Ridge"),
col=c("blue", "red","darkgreen", "darkorange","purple","brown"),
pch=c(1, 1, NA, NA, NA, NA),
lwd=c(NA,NA,1,1,1,1))
fitted_values <- list()
colors <- c("darkgreen","darkorange","purple","brown")
fitted_values[[1]] <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values[[2]] <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values[[3]] <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values[4] <- cbind(1, X) %*% beta
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[[i]]
lines(predictions, col=colors[i])
}
plot(time, data[,1], main="Store Sales vs Time")
for (i in time) {
colors <- ifelse(time %in% Test.indx, "blue", "red")
points(time, data[,1], col=colors, pch=1)
}
legend(x="bottomright",
legend=c("Test Data", "Training Data", "Elastic Net",
"Least Squares", "Least Absolute Error", "Robust Ridge"),
col=c("blue", "red","darkgreen", "darkorange","purple","brown"),
pch=c(1, 1, NA, NA, NA, NA),
lwd=c(NA,NA,1,1,1,1))
fitted_values <- list()
colors <- c("darkgreen","darkorange","purple","brown")
fitted_values[[1]] <- predict(opt_fit,
newx=as.matrix(poly(time,opt_degree)),
s="lambda.min")
fitted_values[[2]] <- predict(ols_fit, newx=poly(time, best_ols_degree))
fitted_values[[3]] <- predict(lad_fit, newx=poly(time, best_lad_degree))
X <- as.matrix(poly(time, optimal_degree))
initial_beta <- rep(1, ncol(X) + 1)
fit <- optim(par = initial_beta,
fn=robust_ridge_loss,
X=cbind(1, X),
y=data[,1])
beta <- fit$par
fitted_values[[4]] <- cbind(1, X) %*% beta
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[[i]]
lines(predictions, col=colors[i])
}
apse_values <- rep(0,4)
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[[i]]
squared_error <- (predictions - data[,1])^2
apse_values[i] <- mean(squared_error)
}
model_apse <- data.frame(Model=c("Elastic Net", "Least Squares", "Least Absolute Error", "Robust Ridge"))
apse_values <- rep(0,4)
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[[i]]
squared_error <- (predictions - data[,1])^2
apse_values[i] <- mean(squared_error)
}
model_apse <- data.frame(Model=c("Elastic Net", "Least Squares", "Least Absolute Error", "Robust Ridge"), APSE=apse_values)
model_apse
apse_values <- rep(0,4)
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[[i]]
squared_error <- (predictions - data[,1])^2
apse_values[i] <- mean(squared_error)
}
model_apse <- data.frame(Model=c("Elastic Net", "Least Squares", "Least Absolute Error", "Robust Ridge"), APSE=apse_values)
model_apse
best_idx <- which.min(model_apse$APSE)
print(paste0("The best model is", model_apse$Model[best_idx]))
apse_values <- rep(0,4)
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[[i]]
squared_error <- (predictions - data[,1])^2
apse_values[i] <- mean(squared_error)
}
model_apse <- data.frame(Model=c("Elastic Net", "Least Squares", "Least Absolute Error", "Robust Ridge"), APSE=apse_values)
model_apse
best_idx <- which.min(model_apse$APSE)
print(paste0("The best model is ", model_apse$Model[best_idx], " as
measured by APSE."))
apse_values <- rep(0,4)
for (i in seq_along(fitted_values)) {
predictions <- fitted_values[[i]]
squared_error <- (predictions - data[,1])^2
apse_values[i] <- mean(squared_error)
}
model_apse <- data.frame(Model=c("Elastic Net", "Least Squares", "Least Absolute Error", "Robust Ridge"), APSE=apse_values)
model_apse
best_idx <- which.min(model_apse$APSE)
print(paste0("The best model is ", model_apse$Model[best_idx], " as measured by APSE."))
Test.idx
Test.indx
View(data)
