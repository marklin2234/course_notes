G.GP = NA,
Leage.average.goals.team.game = NA,
Reg.Season.games = impute_previous_5_years(data, 2005, "Reg.Season.games"),
X.1 = NA
)
data <- bind_rows(data, new_row) %>% arrange(X)
## Normalize data
data <- data$G / data$Reg.Season.games
data.ts <- ts(data, start=1918, end=2024,frequency=1)
raw.training.data <- window(data.ts, end=2002)
raw.test.data <- window(data.ts, start=2003)
orig.test.data <- raw.test.data
# Plot data with training and test set indicated
plot(raw.training.data, col = "firebrick", xlim=c(1916,2025), lwd=2,
main = "Goals per Regular Season Game for Leading Scorer",
ylab = "Goals/# of Regular Season Games (G/RSG)")
lines(raw.test.data, col = "steelblue", lwd=2)
legend("topright", lwd=2,legend = c("Training set", "Test set"),col = c("firebrick", "steelblue"))
# Want to stabilize variance
# Test for optimal lambda(for Box-Cox transformation):
y=as.vector(data.ts)
boxcox.model = boxcox(lm(y~ 1))
optimal.lambda = boxcox.model$x[which.max(boxcox.model$y)]
transformed.data = -data.ts^optimal.lambda
training.data = window(transformed.data, start = 1918, end = 2002)
test.data = window(transformed.data, start = 2003)
print.optimal.lambda = round(optimal.lambda,6)
print(paste0("The optimal lambda to stabilize variance is ", print.optimal.lambda))
# Plot data with training and test set indicated
plot(transformed.data,  lwd=2,
main = "Transformed G/RSG for Leading Scorer",
ylab = "-G/RSG ^ -1.2323")
set.seed(123)
library(dplyr)
library(tidyr)
library(MASS)
data <- read.csv("Data_Group3-Modified.csv", header=TRUE)
data <- data[!duplicated(data$X), ]
data <- data[-1,]
## Impute value
impute_previous_5_years <- function(data, year, column) {
# Get the rows from the previous 5 years
prev_years <- data %>% filter(X < year) %>% arrange(desc(X)) %>% head(5)
# Calculate the mean of the previous 5 years
avg_value <- mean(prev_years[[column]], na.rm = TRUE)
return(avg_value)
}
new_row <- data.frame(
Season = NA,
Player = NA,
X = 2005,
G = impute_previous_5_years(data, 2005, "G"),
GP = NA,
G.GP = NA,
Leage.average.goals.team.game = NA,
Reg.Season.games = impute_previous_5_years(data, 2005, "Reg.Season.games"),
X.1 = NA
)
data <- bind_rows(data, new_row) %>% arrange(X)
## Normalize data
data <- data$G / data$Reg.Season.games
data.ts <- ts(data, start=1918, end=2024,frequency=1)
plot(data.ts)
acf(data.ts)
y=as.vector(data.ts)
boxcox.model = boxcox(lm(y~1))
optimal.lambda = boxcox.model$x[which.max(boxcox.model$y)]
transformed.data = -data.ts^optimal.lambda
training.data = window(transformed.data, start = 1918, end = 2002)
test.data = window(transformed.data, start = 2003)
orig.test.data = window(data.ts, start=2003)
library(glmnet)
# Exponential and double exponential smoothing
ses.model <- HoltWinters(training.data, beta=FALSE,gamma=FALSE)
des.model <- HoltWinters(training.data,gamma=FALSE)
pred.ses <- predict(ses.model,n.ahead=22)
pred.des <- predict(des.model,n.ahead=22)
apse.ses <- mean((pred.ses - test.data)^2)
apse.des <- mean((pred.des - test.data)^2)
apse.ses
apse.des
model <- HoltWinters(transformed.data, beta=FALSE, gamma=FALSE)
fitted.values <- model$fitted[,1]
forecast.values <- predict(model, n.ahead=5)
combined.values <- ts(c(fitted.values, forecast.values),
start=1918,end=2029, frequency=1)
combined.values <- (-combined.values)^(1/optimal.lambda)
plot(data.ts,xlim=c(1918,2029), main = "Simple Exponential Smoothing Model", ylab = "Goals/# of Regular Season Games (G/RSG)")
lines(combined.values, lwd=2, col="red")
# Regression
degrees <- 2:10
poly.t <- poly(as.vector(time(transformed.data)),15)
training.idx <- 1:85
test.idx <- 86:107
alphas <- c(0,0.25,0.5,0.75,1)
optimal_fit <- list()
for (a in alphas) {
apse_values <- c()
for (i in seq_along(degrees)) {
p <- degrees[i]
poly.training.time <- poly.t[-test.idx, 1:p]
poly.test.time <- poly.t[-training.idx, 1:p]
CV <- cv.glmnet(as.matrix(poly.training.time), as.numeric(training.data),
alpha=a,standardize=TRUE,intercept=TRUE)
lambda <- CV$lambda.min
predictions <- predict(CV, newx=as.matrix(poly.test.time), s="lambda.min")
predictions <- (-predictions)^(1/optimal.lambda)
squared_errors <- (predictions - orig.test.data)^2
APSE <- mean(squared_errors)
apse_values <- c(apse_values, APSE)
}
par(mfrow=c(1,2))
plot(degrees, apse_values, main=paste("APSE vs Degree, Alpha = ", a))
deg <- degrees[which.min(apse_values)]
plot(training.data,
main="Fitted Elastic Net Regression Model on Training Data")
poly.training.time <- poly.t[-test.idx, 1:deg]
CV <- cv.glmnet(as.matrix(poly.training.time), as.numeric(training.data),
alpha=a,standardize=TRUE,intercept=TRUE)
fitted_values <- predict(CV, newx=as.matrix(poly.training.time),s="lambda.min")
lines(as.numeric(time(training.data)), fitted_values, col="red", lwd=2)
optimal_fit[[length(optimal_fit) + 1]] <- list(model = CV, degree = deg)
}
apse_values <- c()
for (i in seq_along(optimal_fit)) {
fit <- optimal_fit[[i]]$model
deg <- optimal_fit[[i]]$degree
predictions <- predict(fit, newx=as.matrix(poly.t[-training.idx, 1:deg]), s="lambda.min")
predictions <- (-predictions)^(1/optimal.lambda)
squared_error <- (predictions - orig.test.data)^2
APSE <- mean(squared_error)
apse_values <- c(apse_values, APSE)
print(paste0("Alpha = ", alphas[i], ", Degree = ", deg, ", APSE = ", APSE))
}
opt_idx <- which.min(apse_values)
optimal.regression.model <- optimal_fit[[opt_idx]]$model
optimal.degree <- optimal_fit[[opt_idx]]$degree
print(paste0("The best model is Alpha = ", alphas[opt_idx],
", Degree = ", optimal.degree))
forecast.time <- 2025:2029
poly.forecast.time <- predict(poly.t, newdata=as.numeric(forecast.time))
fitted.values <- predict(optimal.regression.model, newx=as.matrix(poly.t[,1:optimal.degree]),s="lambda.min")
forecast.values <- predict(optimal.regression.model, newx=as.matrix(poly.forecast.time[,1:optimal.degree]),s="lambda.min")
combined.values <- ts(c(fitted.values, forecast.values), start=1918,end=2029, frequency=1)
combined.values <- (-combined.values)^(1/optimal.lambda)
plot(data.ts,xlim=c(1918,2029),main = "Ridge Regression Model (alpha=0, deg=5)", ylab = "Goals/# of Regular Season Games (G/RSG)")
lines(combined.values, lwd=2, col="red")
par(mfrow=c(2,2))
residuals <- (-fitted.values)^(1/optimal.lambda) - data.ts
plot(residuals, main="Residuals")
plot(fitted.values,residuals, main="Fitted vs Residuals")
acf(residuals, "Residual ACF")
qqnorm(residuals, main = "QQ Plot of Residuals")
qqline(residuals, col = "red")
## Some residual diagnostics on this fit.
shapiro.test(residuals)
g <- cut(1:107, breaks=6, labels=1:6)
fligner.test(residuals, g)
randtests::difference.sign.test(residuals)
randtests::runs.test(residuals,plot=TRUE)
## Can use these residuals for ARIMA/SARIMA
#knitr::opts_chunk$set(echo = FALSE,
#                     warning = FALSE,
#                    message = FALSE,
#                   fig.align = "center",
# Two following determine width and height
# of the R device on which the plots are made
#                 fig.width = 8,
#                  fig.height = 9,
# last argument here determines the actual
# width of the plot as it appears in the processed
# RMarkdown file
#                out.width = "75%",
#               out.height = "100%")
# We now want to fit (S)ARIMA models
#par(mfrow=c(1,1))
plot(training.data,
main = "Transformed Training Set",
ylab = "-G/RSG ^ -1.2323")
par(mfrow=c(1,2))
acf(training.data)
pacf(training.data)
# Looking at the plot, we could argue this is stationary
# Looking at the ACF, we could argue that there is exponential decay in the acf
# and hence, training.data is stationary. Note, we are doubtful this is stationary,
# but we will try identifying potential processes anyways
# It looks like the acf cuts off at lag 5 (lag 7 may be a false positive) and
# in the pacf it looks like we have exponential decay
#  --> try MA(5), MA(7)
# OR
# It looks like we have exp decay in the acf and the pacf cuts off after lag 1
# (assuming lag 2 is false positive) or it cuts off after lag 2
# --> try AR(1), AR(2)
# OR
# It looks like we have exp decay in both acf and pacf
# --try ARMA(1,1)
#let's do regular differencing now
Bx <- diff(training.data)
par(mfrow=c(1,1))
plot(Bx,
main = "Differenced (Transformed) Training Set",
ylab = "Bx")
par(mfrow=c(1,2))
acf(Bx)
pacf(Bx)
# This is stationary
#For (s)ARIMA process, we have d = 1
#ARIMA(p,d,q)
# We have exp decay in the pacf, cutoff in acf after either lag 5 or 6
#  --> could argue either MA(5) or MA(6)
#Could also argue we have damped sinusoid in the acf, cutoff after either lag
# 2 or 4 (can argue false positives)
# --> try AR(2), AR(4)
# COuld also argue damped sinusoid in the acf, exp decay in pacf
# --> try ARMA(1,1)
#Our data does not appear to have a seasonal component, so we will only be using
# ARIMA
# Fitting the proposed models:
fit1 <- sarima(training.data, p=0,d=0,q=5,P=0,D=0,Q=0,S=0) # Looks decent
fit2 <- sarima(training.data, p=0,d=0,q=7,P=0,D=0,Q=0,S=0) # Looks decent
fit3 <- sarima(training.data, p=1,d=0,q=0,P=0,D=0,Q=0,S=0) # Bad (Ljung-Box fails)
fit4 <- sarima(training.data, p=2,d=0,q=0,P=0,D=0,Q=0,S=0) # could work, look for better
fit5 <- sarima(training.data, p=1,d=0,q=1,P=0,D=0,Q=0,S=0) # could work, look for better
fit23 <- sarima(training.data, p=2,d=0,q=1,P=0,D=0,Q=0,S=0) # could work,
fit24 <- sarima(training.data, p=1,d=0,q=2,P=0,D=0,Q=0,S=0) # could work
fit25 <- sarima(training.data, p=2,d=0,q=2,P=0,D=0,Q=0,S=0) # could work
fit26 <- sarima(training.data, p=3,d=0,q=2,P=0,D=0,Q=0,S=0) # Good
fit27 <- sarima(training.data, p=2,d=0,q=3,P=0,D=0,Q=0,S=0) # Suspect
fit6 <- sarima(training.data, p=0,d=1,q=5,P=0,D=0,Q=0,S=0) # No (maybe LB fails)
fit7 <- sarima(training.data, p=0,d=1,q=6,P=0,D=0,Q=0,S=0) # Looks good
fit8 <- sarima(training.data, p=2,d=1,q=0,P=0,D=0,Q=0,S=0) # Looks OK
fit9 <- sarima(training.data, p=4,d=1,q=0,P=0,D=0,Q=0,S=0) # Looks good
fit10 <- sarima(training.data, p=1,d=1,q=1,P=0,D=0,Q=0,S=0) # Looks good
fit28 <- sarima(training.data, p=2,d=1,q=1,P=0,D=0,Q=0,S=0) # Could work (a bit sus)
fit29 <- sarima(training.data, p=1,d=1,q=2,P=0,D=0,Q=0,S=0) # Looks good
fit30 <- sarima(training.data, p=2,d=1,q=2,P=0,D=0,Q=0,S=0) # Looks good
# Look at fit of models that passed diagnostics
fit1$ICs
fit2$ICs
fit4$ICs
fit5$ICs
fit7$ICs
fit8$ICs
fit9$ICs
fit10$ICs
fit23$ICs
fit24$ICs
fit25$ICs
fit26$ICs
fit27$ICs
fit28$ICs
fit29$ICs
fit30$ICs
# Some differences in fit, but we care more about prediction power
m.APSE = data.frame(model = NA, APSE = NA)
# Forecasting Chosen models
fore1 <- sarima.for(training.data, n.ahead=22, p=0,d=0,q=5,P=0,D=0,Q=0,S=0)
title("ARIMA(0,0,5)")
lines(test.data,col='blue',type='b',pch=16)
fore2 <- sarima.for(training.data, n.ahead=22, p=0,d=0,q=7,P=0,D=0,Q=0,S=0)
title("ARIMA(0,0,7)")
lines(test.data,col='blue',type='b',pch=16)
fore3 <- sarima.for(training.data, n.ahead=22, p=2,d=0,q=0,P=0,D=0,Q=0,S=0)
title("ARIMA(2,0,0)")
lines(test.data,col='blue',type='b',pch=16)
fore4 <- sarima.for(training.data, n.ahead=22, p=1,d=0,q=1,P=0,D=0,Q=0,S=0)
title("ARIMA(1,0,1)")
lines(test.data,col='blue',type='b',pch=16)
fore5 <- sarima.for(training.data, n.ahead=22, p=0,d=1,q=6,P=0,D=0,Q=0,S=0)
title("ARIMA(0,1,6)")
lines(test.data,col='blue',type='b',pch=16)
fore6 <- sarima.for(training.data, n.ahead=22, p=2,d=1,q=0,P=0,D=0,Q=0,S=0)
title("ARIMA(2,1,0)")
lines(test.data,col='blue',type='b',pch=16)
fore7 <- sarima.for(training.data, n.ahead=22, p=4,d=1,q=0,P=0,D=0,Q=0,S=0)
title("ARIMA(4,1,0)")
lines(test.data,col='blue',type='b',pch=16)
fore8 <- sarima.for(training.data, n.ahead=22, p=1,d=1,q=1,P=0,D=0,Q=0,S=0)
title("ARIMA(1,1,1)")
lines(test.data,col='blue',type='b',pch=16)
fore9 <- sarima.for(training.data, n.ahead=22, p=2,d=0,q=1,P=0,D=0,Q=0,S=0)
title("ARIMA(2,0,1)")
lines(test.data,col='blue',type='b',pch=16)
fore10 <- sarima.for(training.data, n.ahead=22, p=1,d=0,q=2,P=0,D=0,Q=0,S=0)
title("ARIMA(1,0,2)")
lines(test.data,col='blue',type='b',pch=16)
fore11 <- sarima.for(training.data, n.ahead=22, p=2,d=0,q=2,P=0,D=0,Q=0,S=0)
title("ARIMA(2,0,2)")
lines(test.data,col='blue',type='b',pch=16)
fore12 <- sarima.for(training.data, n.ahead=22, p=3,d=0,q=2,P=0,D=0,Q=0,S=0)
title("ARIMA(3,0,2)")
lines(test.data,col='blue',type='b',pch=16)
fore13 <- sarima.for(training.data, n.ahead=22, p=2,d=0,q=3,P=0,D=0,Q=0,S=0)
title("ARIMA(2,0,3)")
lines(test.data,col='blue',type='b',pch=16)
fore14 <- sarima.for(training.data, n.ahead=22, p=2,d=1,q=1,P=0,D=0,Q=0,S=0)
title("ARIMA(2,1,1)")
lines(test.data,col='blue',type='b',pch=16)
fore15 <- sarima.for(training.data, n.ahead=22, p=1,d=1,q=2,P=0,D=0,Q=0,S=0)
title("ARIMA(1,1,2)")
lines(test.data,col='blue',type='b',pch=16)
fore16 <- sarima.for(training.data, n.ahead=22, p=2,d=1,q=2,P=0,D=0,Q=0,S=0)
title("ARIMA(2,1,2)")
lines(test.data,col='blue',type='b',pch=16)
forecasted.models = list(fore1, fore2, fore3, fore4, fore5,
fore6, fore7, fore8, fore9, fore10, fore11, fore12, fore13,
fore14, fore15, fore16)
fore.APSE = c()
# Calculate APSE for each model above
for (fore.model in forecasted.models){
pred.vals = (-fore.model$pred)^(1/optimal.lambda)
m.APSE = mean((raw.test.data - pred.vals)^2)
fore.APSE = c(fore.APSE, m.APSE)
}
arima.APSE = data.frame(model = NA, APSE = NA)
models = c("ARIMA(0,0,5)", "ARIMA(0,0,7)", "ARIMA(2,0,0)", "ARIMA(1,0,1)",
"ARIMA(0,1,6)", "ARIMA(2,1,0)", "ARIMA(4,1,0)", "ARIMA(1,1,1)",
"ARMA(2,1)", "ARMA(1,2)", "ARMA(2,2)",
"ARMA(3,2)", "ARMA(2,3)", "ARIMA(2,1,1)", "ARIMA(1,1,2)", "ARIMA(2,1,2)")
for (i in (1:length(models))){
arima.APSE[i,] = c(models[i], round(fore.APSE[i],8))
}
print(arima.APSE)
# Best model based on APSE:
#arima.APSE[which.min(arima.APSE$APSE),]
library(glmnet)
degrees <- 2:10
poly.t <- poly(as.vector(time(transformed.data)),15)
training.idx <- 1:85
test.idx <- 86:107
alphas <- c(0,0.25,0.5,0.75,1)
optimal_fit <- list()
for (a in alphas) {
apse_values <- c()
for (i in seq_along(degrees)) {
p <- degrees[i]
poly.training.time <- poly.t[-test.idx, 1:p]
poly.test.time <- poly.t[-training.idx, 1:p]
CV <- cv.glmnet(as.matrix(poly.training.time), as.numeric(training.data),
alpha=a,standardize=TRUE,intercept=TRUE)
lambda <- CV$lambda.min
predictions <- predict(CV, newx=as.matrix(poly.test.time), s="lambda.min")
predictions <- (-predictions)^(1/optimal.lambda)
squared_errors <- (predictions - orig.test.data)^2
APSE <- mean(squared_errors)
apse_values <- c(apse_values, APSE)
}
par(mfrow=c(1,2))
plot(degrees, apse_values, main=paste("APSE vs Degree, Alpha = ", a))
deg <- degrees[which.min(apse_values)]
plot(training.data,
main="Fitted Elastic Net Regression Model on Training Data")
poly.training.time <- poly.t[-test.idx, 1:deg]
CV <- cv.glmnet(as.matrix(poly.training.time), as.numeric(training.data),
alpha=a,standardize=TRUE,intercept=TRUE)
fitted_values <- predict(CV, newx=as.matrix(poly.training.time),s="lambda.min")
lines(as.numeric(time(training.data)), fitted_values, col="red", lwd=2)
optimal_fit[[length(optimal_fit) + 1]] <- list(model = CV, degree = deg)
}
apse_values <- c()
for (i in seq_along(optimal_fit)) {
fit <- optimal_fit[[i]]$model
deg <- optimal_fit[[i]]$degree
predictions <- predict(fit, newx=as.matrix(poly.t[-training.idx, 1:deg]), s="lambda.min")
predictions <- (-predictions)^(1/optimal.lambda)
squared_error <- (predictions - orig.test.data)^2
APSE <- mean(squared_error)
apse_values <- c(apse_values, APSE)
print(paste0("Alpha = ", alphas[i], ", Degree = ", deg, ", APSE = ", APSE))
}
opt_idx <- which.min(apse_values)
optimal.regression.model <- optimal_fit[[opt_idx]]$model
optimal.degree <- optimal_fit[[opt_idx]]$degree
print(paste0("The best Elastic Net regression model is Alpha = ", alphas[opt_idx],
", Degree = ", optimal.degree))
forecast.time <- 2025:2033
poly.forecast.time <- predict(poly.t, newdata=as.numeric(forecast.time))
fitted.values <- predict(optimal.regression.model, newx=as.matrix(poly.t[,1:optimal.degree]),s="lambda.min")
forecast.values <- predict(optimal.regression.model, newx=as.matrix(poly.forecast.time[,1:optimal.degree]),s="lambda.min")
combined.values <- ts(c(fitted.values, forecast.values), start=1918,end=2033, frequency=1)
combined.values <- (-combined.values)^(1/optimal.lambda)
## Some residual diagnostics on this fit.
#Residuals for TRAINING SET
#fit.reg <- optimal_fit[[opt_idx]]$model
#deg.reg <- optimal_fit[[opt_idx]]$degree
fitted.reg <- predict(optimal.regression.model, newx=as.matrix(poly.t[-test.idx, 1:optimal.degree]), s="lambda.min")
fitted.reg <- (-fitted.reg)^(1/optimal.lambda)
residuals.reg <- raw.training.data - fitted.reg
#Residuals for predicted values against test set
fitted.reg.test <- predict(optimal.regression.model, newx=as.matrix(poly.t[-training.idx, 1:optimal.degree]), s="lambda.min")
predicted.reg.test <- (-fitted.reg.test)^(1/optimal.lambda) # Transform back to back to original scale
residuals.reg.test <- orig.test.data - predicted.reg.test
#Residuals FOR ENTIRE DATASET
residuals <- transformed.data - fitted.values
fitted.values.orig.scale = (-fitted.values)^(1/optimal.lambda)
reg.residuals.all = data.ts - fitted.values.orig.scale
# Do Box-Jenkins on residuals from regression
par(mfrow=c(1,1))
plot(residuals.reg, ylab = "G/RSG", main = "Residuals from Optimal Regression Model")
par(mfrow=c(1,2))
acf(residuals.reg, main="Residuals from Regression")
pacf(residuals.reg, main="Residuals from Regression")
# data looks stationary since no linear decay in acf
#    --> proceed with Box-Jenkins
# ACF cuts after lag 6 can argue PACF has very fast exp decay --> try MA(6)
#PACF cuts after lag 6 ,Acf has exp decay --> try AR(6)
# Can argue both ACF & PACF decay exponentially --> try ARMA(p,q) starting with
#  p=1,q=1 and proceed from there
fit11 <- sarima(residuals.reg, p=0,d=0,q=6,P=0,D=0,Q=0,S=0) # Looks good
fit12 <- sarima(residuals.reg, p=6,d=0,q=0,P=0,D=0,Q=0,S=0) # Lung-Box is sus --> fail
fit13 <- sarima(residuals.reg, p=1,d=0,q=1,P=0,D=0,Q=0,S=0) # Bad -> drop
# (p,q) between (1,1) and (3,3) did not look good (failed Ljung-Box)
fit14 <- sarima(residuals.reg, p=4,d=0,q=3,P=0,D=0,Q=0,S=0) # Looks good
fit15 <- sarima(residuals.reg, p=3,d=0,q=4,P=0,D=0,Q=0,S=0) # fail
fit16 <- sarima(residuals.reg, p=4,d=0,q=4,P=0,D=0,Q=0,S=0) # good
fit17 <- sarima(residuals.reg, p=5,d=0,q=4,P=0,D=0,Q=0,S=0) #good
fit18 <- sarima(residuals.reg, p=4,d=0,q=5,P=0,D=0,Q=0,S=0) #good
fit19 <- sarima(residuals.reg, p=6,d=0,q=5,P=0,D=0,Q=0,S=0) # fail
fit20 <- sarima(residuals.reg, p=5,d=0,q=6,P=0,D=0,Q=0,S=0) #fail
fit21 <- sarima(residuals.reg, p=5,d=0,q=5,P=0,D=0,Q=0,S=0) # good
fit22 <- sarima(residuals.reg, p=6,d=0,q=6,P=0,D=0,Q=0,S=0) #good
# Started with (p=1,q=1), trying different combinations
#Compare the quality of fit of remaining models:
fit11$ICs
fit14$ICs
fit16$ICs
fit17$ICs
fit18$ICs
fit21$ICs
fit22$ICs
# Overall, there are some differences in fit, but we care more about prediction power
#   --> look at APSE
# Forecast test data
fore1.reg <- sarima.for(residuals.reg, n.ahead=22, p=0,d=0,q=6,P=0,D=0,Q=0,S=0)
title("ARIMA(0,0,6) Using Regression Residuals")
lines(orig.test.data,col='blue',type='b',pch=16)
fore2.reg <- sarima.for(residuals.reg, n.ahead=22, p=4,d=0,q=3,P=0,D=0,Q=0,S=0)
title("ARIMA(4,0,3) Using Regression Residuals")
lines(orig.test.data,col='blue',type='b',pch=16)
fore3.reg <- sarima.for(residuals.reg, n.ahead=22, p=4,d=0,q=4,P=0,D=0,Q=0,S=0)
title("ARIMA(4,0,4) Using Regression Residuals")
lines(orig.test.data,col='blue',type='b',pch=16)
fore4.reg <- sarima.for(residuals.reg, n.ahead=22, p=5,d=0,q=4,P=0,D=0,Q=0,S=0)
title("ARIMA(5,0,4) Using Regression Residuals")
lines(orig.test.data,col='blue',type='b',pch=16)
fore5.reg <- sarima.for(residuals.reg, n.ahead=22, p=4,d=0,q=5,P=0,D=0,Q=0,S=0)
title("ARIMA(4,0,5) Using Regression Residuals")
lines(orig.test.data,col='blue',type='b',pch=16)
fore6.reg <- sarima.for(residuals.reg, n.ahead=22, p=5,d=0,q=5,P=0,D=0,Q=0,S=0)
title("ARIMA(5,0,5) Using Regression Residuals")
lines(orig.test.data,col='blue',type='b',pch=16)
fore7.reg <- sarima.for(residuals.reg, n.ahead=22, p=6,d=0,q=6,P=0,D=0,Q=0,S=0)
title("ARIMA(6,0,6) Using Regression Residuals")
lines(orig.test.data,col='blue',type='b',pch=16)
forecasted.reg.models = list(fore1.reg, fore2.reg, fore3.reg, fore4.reg, fore5.reg,
fore6.reg, fore7.reg)
fore.reg.APSE = c()
# Calculate APSE for each model above
for (fore.model in forecasted.reg.models){
# Add predicted residuals to predicted regression trend
pred.vals = predicted.reg.test + fore.model$pred
m.APSE = mean((raw.test.data - pred.vals)^2)
fore.reg.APSE = c(fore.reg.APSE, m.APSE)
}
reg.arima.APSE = data.frame(model = NA, APSE = NA)
reg.models = c("MA(6)", "ARMA(4,3)", "ARMA(4,4)", "ARMA(5,4)",
"ARMA(4,5)", "ARMA(5,5)", "ARMA(6,6)")
for (i in (1:7)){
reg.arima.APSE[i,] = c(reg.models[i], round(fore.reg.APSE[i],8))
}
# Compare APSE from data & differenced data to regression residuals
# APSE from Box-Jenkins on data & differenced data
print(arima.APSE)
#Sort by order of APSE so it's easier to compare
sort.arima.APSE = arima.APSE[order(arima.APSE$APSE),]
sort.reg.arima.APSE = reg.arima.APSE[order(reg.arima.APSE$APSE),]
# APSE for Box-Jenkins on regression residuals
print(sort.reg.arima.APSE)
# Fit 2 models with lowest APSE to entire dataset
#  ARIMA(1,0,1) on data,
#
#Forecasting the future 5 years. Notice that we are using the whole dataset this time.
# Forecast rend using optimal regression model
forecast.time <- 2025:2029
poly.forecast.time <- predict(poly.t, newdata=as.numeric(forecast.time))
fitted.values <- predict(optimal.regression.model, newx=as.matrix(poly.t[,1:optimal.degree]),s="lambda.min")
forecast.values <- predict(optimal.regression.model, newx=as.matrix(poly.forecast.time[,1:optimal.degree]),s="lambda.min")
forecast.values <- (-forecast.values)^(1/optimal.lambda)
combined.values <- ts(c(fitted.values, forecast.values), start=1918,end=2029, frequency=1)
combined.values <- (-combined.values)^(1/optimal.lambda) # fitted & predicted values (orig scale)
#Forecast residuals
future.residuals <- sarima.for(reg.residuals.all, n.ahead=5,
p=5,d=0,q=5,P=0,D=0,Q=0,S=0)
Final.residuals <- sarima(reg.residuals.all,p=5,d=0,q=5,P=0,D=0,Q=0,S=0)
# Add projected trend (from regression) + projected residuals
Final.projected.values = forecast.values + future.residuals$pred
#Note this Pred interval is only for the residuals
# (we do not know how to get prediction interval from Ridge Regression)
lower <- future.residuals$pred-1.96*future.residuals$se + forecast.values
upper <- future.residuals$pred+1.96*future.residuals$se +forecast.values
yband <- c(0.35,2.2)
plot(data.ts,xlim=c(1915,2030),ylim=yband,
ylab='G/RSG',main='Predicting Using Regression + ARMA(5,5) on Residuals',col = "black")
#lines(window(Final.projected.values, start=1918, end=2024), col= "firebrick2")
lines(Final.projected.values, col="firebrick2", type='b', pch=16,cex=0.5)
x = c(time(upper) , rev(time(upper)))
y = c(upper , rev(lower))
polygon(x, y, col = "grey" , border =NA)
#lines(fit,col='red',type='b',pch=16 , cex=0.5)
lines(lower,col='black',lty=2)
lines(upper,col='black',lty=2)
lines(Final.projected.values, col="firebrick2", type='b', pch=16,cex=0.5)
