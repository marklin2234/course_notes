---
title: "STAT 341: Assignment 4"
subtitle: 'DUE: Friday, April 5, 2024 by 5:00pm EDT'
output:
  pdf_document: default
  word_document: default
  html_document: default
urlcolor: blue
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r, include = FALSE}
library(knitr)
#opts_chunk$set(tidy.opts=list(width.cutoff=70),tidy=TRUE)
knitr::opts_chunk$set(cache=TRUE)
```

$\;$ $\;$ $\;$ $\;$

## NOTES

Your assignment must be submitted by the due date listed at the top of this document, and it must be submitted electronically in .pdf format via Crowdmark. This means that your responses for different question parts should begin on separate pages of your .pdf file. Note that your .pdf solution file must have been generated by R Markdown. Additionally:

-   For mathematical questions: your solutions must be produced by LaTeX (from within R Markdown). Neither screenshots nor scanned/photographed handwritten solutions will be accepted -- these will receive zero points.

-   For computational questions: R code should always be included in your solution (via code chunks in R Markdown). If code is required and you provide none, you will receive zero points.

    -   **Exception** any functions used in the notes or function glossary can loaded using `echo=FALSE` but any other code chunks should have `echo=TRUE`. e.g. the code chuck loading `calculatePVmulti` can use `echo=FALSE` but chunks that call `calculatePVmulti` should have `echo=TRUE`.

-   For interpretation questions: plain text (within R Markdown) is required. Text responses embedded as comments within code chunks will not be accepted.

Organization and comprehensibility is part of a full solution. Consequently, points will be deducted for solutions that are not organized and incomprehensible. Furthermore, if you submit your assignment to Crowdmark, but you do so incorrectly in any way (e.g., you upload your Question 2 solution in the Question 1 box), you will receive a 5% deduction (i.e., 5% of the assignment’s point total will be deducted from your point total).

\newpage

## THE DATA

*Online controlled experiments* seek to use user-generated data to test and improve internet-based products and services. Informally referred to as A/B tests, these experiments are an indispensable tool for major technology companies when it comes to maximizing revenue and optimizing the user experience. Industry giants run hundreds of experiments on millions of users every day, testing changes to websites, services, and installed software; desktop and mobile devices; front- and back-end product features; personalization and recommendations; and monetization strategies. This type of experimentation is ubiquitous in the tech industry. If you've been on the internet today, you've been a subject in one of these experiments.

```{=tex}
\begin{center}
\includegraphics[width=5in]{asos.png}
\end{center}
```
This assignment will have you, with randomization tests and bootstrapped confidence intervals, analyze an A/B test from [ASOS.com](https://www.asos.com/): an online fashion and cosmetics retailer that targets young adults in North America, Europe, and Oceania. ASOS recently published a [repository of data from 78 experiments](https://osf.io/64jsb/) run on their website in 2019 and 2020. You will be working with data associated with one of these experiments.

In particular, suppose interest lies in evaluating whether adding a "free delivery" banner to the homepage materially impacts users' shopping behaviour. To assess this, an experiment is run in which some users to the ASOS homepage see such a banner (these users are in the *treatment* group), while other users see the original website with no mention of free shipping (these users are in the *control* group). Whether a user is in the treatment or control group is random, so any difference in purchasing behaviour between these groups can be attributed to the presence/absence of the "free delivery" banner. Purchase behaviour may be quantified in many ways (e.g., by recording whether a purchase was made, the number of items purchased, or the total order value).

In this experiment, the focus is on determining whether the "free delivery" banner is associated with an increase in total order value. The experiment ran for 19 days and engaged over 2 million users to ASOS.com. However, to keep calculations manageable, you will work with observations on just $n=5,536$ users. The table below describes the variates recorded for each of these users. This data is available in the file `asos.csv`.

| Variate       | Description                                                                                                                                           |
|---------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| `Day`         | This variate takes on the values `1:19` indicating which day of the experiment the user was observed.                                                 |
| `Order.Value` | This is a numeric variate indicating the total amount spent (in £) by the user.                                                                       |
| `Version`     | This is a categorical variate taking on the values `"T"` or `"C"` respectively indicating whether the user was in the *treatment* or *control* group. |

\newpage

## QUESTION 1: Randomization Tests [21 points]

(a) [2 points] Read in the data and calculate a `summary()` of `Order.Value` for the treatment and control groups separately.

```{r}
data <- read.csv("asos.csv")
summary(data[data$Version == "T",])
summary(data[data$Version == "C",])

```

(b) [4 points] Construct a QQ (i.e., quantile-quantile) plot comparing the quantiles of `Order.Value` in the treatment and control groups. Specifically, calculate quantiles of `Order.Value` for `p = seq(from=0, to=1, by=0.01)` for both groups, and create a scatter plot of these pairs with control quantiles on the $x$-axis. Add the line of equality ($y=x$) to the plot. Be sure to include an informative title and axis labels. Note that you *may not use* the `qqplot()` function, but you can use it to check your answer.

```{r}
p = seq(from = 0, to = 1, by = 0.01)
x = quantile(data[data$Version == "C",]$Order.Value, p)
y = quantile(data[data$Version == "T",]$Order.Value, p)

plot(x,y, xlab = 'Control Quantiles', ylab = 'Order Value', main='Control vs Order Quantiles')
abline(a = 0, b = 1)
```

(c) [2 points] By addressing both the summaries in (a) and the plot in (b), comment on the following:

    -   What appears to be a typical `Order.Value` in each group?
    -   Does `Order.Value` appear to depend on whether a "free delivery" banner is shown?

-   A typical Order.Value in each group is 0-500.
-   No

(d) [1 point] Define $\mathcal{S}_{T}$ and $\mathcal{S}_{C}$ as the `Order.Value` observations for users in the treatment and control groups, respectively[^1]. State the null hypothesis $H_0$ that is being tested when comparing these two sub-populations with a randomization test.

[^1]: Note that we use sample notation (i.e., $\mathcal{S}_{T}$ and $\mathcal{S}_{C}$) here instead of population notation (i.e., $\mathcal{P}_{T}$ and $\mathcal{P}_{C}$) to acknowledge that the users in the experiment are a *subset* of all of the ASOS.com users.

$H_0$ is defined as there is no difference between the treatment and control groups. Thus, $H_0: \mathcal{S}_{T} =\mathcal{S}_{C}$

$\;$

(e) [5 points] In this question, you will test the hypothesis in (d) using the discrepancy measure $$D(\mathcal{S}_{T},\mathcal{S}_{C}) = |\overline{y}_T - \overline{y}_C|$$

    i.  [1 point] Calculate the observed discrepancy.

    ```{r}
    mean_T <- mean(data[data$Version == "T",]$Order.Value)
    mean_C <- mean(data[data$Version == "C",]$Order.Value)
    D <- abs(mean_T - mean_C)
    D
    ```

    ii. [2 points] Randomly mix the populations $M=1000$ times and construct a histogram of the 1000 $D(\mathcal{S}_{T}^\star,\mathcal{S}_{C}^\star)$ values. Indicate, with a vertical line, the observed discrepancy calculated in i. Note that you may use the `mixRandomly()` function from class. For your convenience, the function is included in the Appendix at the end of the assignment.

```{r}
  mixRandomly <- function(p) {
  p1 <- p$pop1
  n1 <- nrow(p1)
  p2 <- p$pop2
  n2 <- length(p2)
  mix <- rbind(p1, p2)
  select <- sample(1:(n1 + n2), n1, replace = FALSE) 
  newp1 <- mix[select,]
  newp2 <- mix[-select,]
  list(pop1 = newp1, pop2 = newp2)
}

x <- c()
for (i in 1:1000) {
    p <- mixRandomly(list(pop1 = data[data$Version == "T",],
    pop2=data[data$Version == "C",]))
    dis <- abs(mean(p$pop1$Order.Value) - mean(p$pop2$Order.Value))
    x <- c(x, dis)
}
hist(x, xlab="Idx", ylab="Discrepancy Measures", main="Histogram of Discrepancy Measures",prob=TRUE)
abline(v=D,col="RED",lwd=2)
```

```         
iii. [1 point] Calculate the $p\text{-value}$ associated with this test.
```

```{r}
p <- mean(x >= D)
p
```

```         
iv. [1 point] Based on the $p\text{-value}$ calculated in iii., what do you conclude about the comparability of these two sub-populations? In other words, summarize your findings and draw a conclusion about the null hypothesis from part (d). By referring to the summaries calculated in part (a), explain why this conclusion is, or is not, surprising.
```

There is not enough evidence to reject the null hypothesis. This is not very surprising since the summaries in part a) are quite similar.

(f) [5 points] The comparison in (e) was based just on means. For a more holistic comparison of the `Order.Value` distributions, we could compare several quantiles, such as $Q(0)$, $Q(0.25)$, $Q(0.5)$, $Q(0.75)$, $Q(1)$. However, increasing the number of comparisons increases the magnitude of the *multiple testing* problem and so we must be careful to account for this. In this question, you will test the hypothesis in (d) using the discrepancy measure $$D(\mathcal{S}_{T},\mathcal{S}_{C}) = |Q_T(p) - Q_C(p)|$$ for $p\in\{0,0.25,0.5,0.75,1\}$, and you will account for the multiple testing problem by using the `calculatePVmulti()` function from class. For your convenience, the function is included in the Appendix at the end of the assignment.

    Also defined below is `getQCompFn`, a factory function of a single input `p` that outputs a function which calculates the absolute difference in `p` quantiles of `Order.Value` between the treatment and control groups. This will be useful in part i. below.

    ```{r}
    getQCompFn <- function(p){
     function(pop) {
      as.numeric(abs(quantile(pop[[2]]$Order.Value, p) - quantile(pop[[1]]$Order.Value, p)))
     }
    }
    ```

    i.  [1 point] Use the factory function `getQCompFn` to create 5 functions `absDiffQ0`, `absDiffQ25`, `absDiffQ50`, `absDiffQ75`, and `absDiffQ100` which each take as input a 2-element list that respectively return the absolute difference in quantiles for treatment vs. control for $p=0,0.25,0.5,0.75,1$. Then use each these functions to calculate $D(\mathcal{S}_{T},\mathcal{S}_{C}) = |Q_T(p) - Q_C(p)|$ for each $p$.

    ii. [2 points] Estimate $p\text{-value}^{\star}$, the $p\text{-value}$ associated with a test of $H_0$ from part (d), that simultaneously accounts for the five discrepancy measures defined in ii. Use the `calculatePVmulti()` together with the discrepancy functions you defined in i., and use `M_inner = M_outer = 100`.

    iii. [2 points] Based on $p\text{-value}^{\star}$ calculated in ii., what do you conclude about the comparability of these two sub-populations? In other words, summarize your findings and draw a conclusion about the null hypothesis from part (d). By referring to the QQ-plot constructed in part (b), explain why this conclusion is, or is not, surprising.

$\;$

(g) [2 points] Explain in your own words what the *multiple testing* problem is, and briefly explain why the approach taken in part (f) is to be preferred to considering five separate tests based on $|Q_T(0) - Q_C(0)|$, $|Q_T(0.25) - Q_C(0.25)|$, $|Q_T(0.5) - Q_C(0.5)|$, $|Q_T(0.75) - Q_C(0.75)|$, and $|Q_T(1) - Q_C(1)|$ individually.

\newpage

## QUESTION 2: Bootstrap Confidence Intervals [25 points]

In Question 1, you conducted hypothesis tests to determine whether there was a significant difference in order values when users are vs. are not shown a "free delivery" banner. In this question, you will turn your focus to (point and interval) estimation of the *treatment effect*, a quantification of the impact on `Order.Value` of the treatment relative to the control. Treatment impact can be quantified in a variety of ways; here you will focus on the *average treatment effect* $$\text{ATE} = \overline{y}_T-\overline{y}_C$$ and also the percent treatment effect, referred to in A/B testing settings as *lift*: $$\text{lift} = \frac{\overline{y}_T-\overline{y}_C}{\overline{y}_C}$$ where $$\overline{y}_T = \frac{1}{n_T}\sum_{u\in\mathcal{S}_T}y_u ~~~~ \text{and} ~~~~ \overline{y}_C = \frac{1}{n_C}\sum_{u\in\mathcal{S}_C}y_u$$ are the average order values in the treatment and control groups, respectively.

(a) [4 points] Consider the following simple linear regression model $$y_u = \alpha + \beta~x_u+r_u, ~~~~ u\in\mathcal{S}=\mathcal{S}_T\cup\mathcal{S}_C$$ where $y_u$ represents the `Order.Value` of user $u$ and $x_u$ is a treatment assignment indicator defined as follows: $$x_u =
      \begin{cases}
    1 & \text{if user}~u~\text{is in the treatment group} \\
    0 & \text{if user}~u~\text{is in the control group}
      \end{cases}.$$ Earlier in the course, it was established that the least squares estimates of $\alpha$ and $\beta$ are $$\hat\alpha=\overline{y}-\hat\beta~\overline{x} ~~~~ \text{and} ~~~~ \hat\beta=\frac{\sum_{u\in\mathcal{S}}(x_u-\overline{x})(y_u-\overline{y})}{\sum_{u\in\mathcal{S}}(x_u-\overline{x})^2}$$ where $\overline{x} = \sum_{u\in\mathcal{S}}x_u/n$, $\overline{y} = \sum_{u\in\mathcal{S}}y_u/n$, and $n= n_T + n_C$.

    $\;$

    For $x_u$ and $y_u$ as defined above, show that $$\hat\alpha = \overline{y}_C~~~~ \text{and} ~~~~\hat\beta=\overline{y}_T-\overline{y}_C$$ and hence that $\text{ATE}=\hat\beta$ and $\text{lift}=\hat\beta/\hat\alpha$.

    **Hints:**

    -   $\sum_{u\in\mathcal{S}}x_u = n_T$
    -   $\sum_{u\in\mathcal{S}}y_ux_u = \sum_{u\in\mathcal{S}_T}y_u = n_T\overline{y}_T$
    -   $x_u^2=x_u ~~\forall~ u$

$\;$

$$
\hat\alpha
$$

(b) [2 points] Using the `lm()` function, fit the linear regression model above and calculate the $\text{ATE}$ and $\text{lift}$ for this A/B test.

```{r}
data$Version <- ifelse(data$Version == "T", 1, 0)
fit <- lm(data$Order.Value ~ data$Version)
coeffs <- coefficients(fit)
alpha <- coeffs[[1]]; beta <- coeffs[[2]]
ATE <- beta
lift <- beta/alpha
print(paste0("ATE: ", ATE))
print(paste0("lift: ", lift))
```

(c) [2 points] By resampling $\mathcal{S}$ with replacement, construct $B=1000$ bootstrap samples $\mathcal{S}_1^\star,\mathcal{S}_2^\star,\ldots,\mathcal{S}_{1000}^\star$. Print out your code, not the 1000 samples. Note that the units in $\mathcal{S}$ should be regarded as the $(x_u,y_u)$ pairs. Thus the pairs themselves should be resampled with replacement.

```{r}
B <- 1000
samples <- list()
for (b in 1:B) {
  samples[[b]] <- data[sample(nrow(data), nrow(data), replace=TRUE), c("Order.Value", "Version")]
}
```

(d) [6 points] For each of the $B=1000$ bootstrap samples in part (c), use `lm()` to calculate the least squares estimates $\hat\alpha^\star$ and $\hat\beta^\star$ and hence $\text{ATE}^\star$ and hence $\text{lift}^\star$ in each bootstrap sample $\mathcal{S}_b^\star, ~~ b=1,2,...,B.$ Construct two histograms, one of the $\text{ATE}^\star$ values and the other of the $\text{lift}^\star$ values. Include a vertical line representing $\text{ATE}$ from (b) on the first histogram and a line representing $\text{lift}$ from (b) in the second. Be sure to informatively label your plots.

```{r}
ATE_stars <- c()
lift_stars <- c()
for (b in 1:B) {
  sample <- samples[[b]]
  fit <- lm(sample$Order.Value ~ sample$Version)
  coeffs <- coefficients(fit)
  alpha <- coeffs[[1]]; beta <- coeffs[[2]]
  ATE_stars <- c(ATE_stars, beta)
  lift_stars <- c(lift_stars, beta/alpha)
}
hist(ATE_stars,prob=TRUE)
abline(v=ATE,col="RED",lwd=2)
hist(lift_stars,prob=TRUE)
abline(v=lift,col="RED",lwd=2)
```

(e) [2 points] Calculate 95% confidence intervals for $\text{ATE}$ and $\text{lift}$ using the naive normal theory approach.

```{r}
cat("ATE CI: (", ATE + 1.96 * c(-1,1) * sd(ATE_stars),")\n")
cat("lift CI: (", lift + 1.96 * c(-1,1) * sd(lift_stars), ")")
```

(f) [2 points] Calculate 95% confidence intervals for $\text{ATE}$ and $\text{lift}$ using the percentile method.

```{r}
print(paste0("ATE CI: (:", quantile(ATE_stars, probs=0.025), ", ", quantile(ATE_stars, prob=0.9725), ")"))
print(paste0("lift CI: (", quantile(lift_stars, probs=0.025), ", ", quantile(lift_stars, prob=0.9725), ")"))
```

(g) [4 points] Calculate 95% confidence intervals for $\text{ATE}$ and $\text{lift}$ using the bootstrap-$t$ approach. You should use the `bootstrap_t_interval_new()` function included in the Appendix. Note that this is a modified version of the `bootstrap_t_interval()` function from class that accommodates a data frame (instead of a vector) for the input `S`. For the input `a`, you will also need to write functions that calculate $\text{ATE}$ and $\text{lift}$ given a data frame that includes columns for `Order.Value` and `Version`. Please use $B=100$ and $D=100$.

```{r}
bootstrap_t_interval_new <- function(S, a, confidence, B, D, ...) {
  ## S = an n row data frame containing the variate values in the sample
  ## a = a scalar-valued function that calculates the attribute a() of interest
  ## confidence = a value in (0,1) indicating the confidence level
  ## B = a numeric value representing the outer bootstrap count of
  ## replicates (used to calculate the lower and upper limits)
  ## D = a numeric value representing the inner bootstrap count of replicates
  ## (used to estimate the standard deviation of the sample attribute for
  ## each (outer) bootstrap sample)
  aS <- a(S)
  sampleSize <- nrow(S)
  ## get (outer) bootstrap values
  bVals <- sapply(1:B, FUN = function(b) {
    Sstar.idx <- sample(1:sampleSize, sampleSize, replace = TRUE)
    aSstar <- a(S[Sstar.idx,])
    ## get (inner) bootstrap values to estimate the SD
    SD_aSstar <- sd(sapply(1:D, FUN = function(d) {
    Sstarstar.idx <- sample(Sstar.idx, sampleSize, replace = TRUE)
    ## return the attribute value
    a(S[Sstarstar.idx,])
    }))
    z <- (aSstar - aS)/SD_aSstar
    ## Return the two values
    c(aSstar = aSstar, z = z)
  })
  SDhat <- sd(bVals["aSstar", ])
  zVals <- bVals["z", ]
  ## Now use these zVals to get the lower and upper c values.
  cValues <- quantile(zVals, probs = c((1 - confidence)/2, (confidence +
    1)/2), na.rm = TRUE)
  cLower <- min(cValues)
  cUpper <- max(cValues)
  interval <- c(lower = aS - cUpper * SDhat, middle = aS, upper = aS -
    cLower * SDhat)
  return(interval)
}

findATE <- function(S) {
  fit <- lm(S$Order.Value ~ S$Version)
  coeffs <- coefficients(fit)
  beta <- coeffs[[2]]
  beta
}

findlift <- function(S) {
  fit <- lm(S$Order.Value ~ S$Version)
  coeffs <- coefficients(fit)
  alpha <- coeffs[[1]]; beta <- coeffs[[2]]
  beta/alpha
}

bootstrap_t_interval_new(data[, !(names(data) == "Day")], findATE, 0.95, 100, 100)
bootstrap_t_interval_new(data[, !(names(data) == "Day")], findlift, 0.95, 100, 100)
```

(h) [3 points] This question concerns advantages and disadvantages associated with the various methods of confidence interval calculation you've explored.

    i.  [1 point] List one advantage and one disadvantage of naive normal theory intervals. $\widehat{SD}(\bar{Y})$ can be estimated using the standard deviation of the bootstrap distribution of $\bar{Y}$ which is an advantage because this approach can be used for any attribute $a(S)$. A disadvantage of this method is that it only applies if the bootstrap distribution is approximately normal.

    ii. [1 point] List one advantage and one disadvantage of percentile method intervals. This method is equivariant ot any 1:1 transformation of the attribute and incredibly simple, but is often incorrect unless the distribution of the estimator is not nearly symmetric.

    iii. [1 point] List one advantage and one disadvantage of bootstrap-$t$ intervals. An advantage is that it automatically adjusts its shape to the form of our attribute of interest. A disadvantage is that this requires computation.

$\;$

$\;$

## QUESTION 3: Wrap Up [2 points]

In two sentences, summarize your findings from questions 1 and 2 and draw an overall conclusion about the efficacy of the "free delivery" banner on total order value.

The free delivery banner on total order value is not very effective.

## QUESTION 4: (Optional) Practice Interview Questions [0 points]

Here are four very common data science interview questions related to the material covered on this assignment. In preparation for your own interviews, or the final exam perhaps, think about how you would answer them. In all cases, imagine you're discussing these things with the Senior Data Scientist who is interviewing you. You do not need to submit answers for these.

(a) [0 points] In your own words, explain what a p-value is.

(b) [0 points] In your own words, explain what the randomization test is, and why it's useful.

(c) [0 points] In your own words, explain what it means to be "95% confident" in a 95% confidence interval.

(d) [0 points] In your own words, explain what resampling methods like the bootstrap are, and why they are useful.

\newpage

## APPENDIX

Useful functions.

```{r, eval=FALSE}
mixRandomly <- function(pop) {
  pop1 <- pop$pop1
  n_pop1 <- nrow(pop1)
  pop2 <- pop$pop2
  n_pop2 <- nrow(pop2)
  mix <- rbind(pop1, pop2)
  select4pop1 <- sample(1:(n_pop1 + n_pop2), n_pop1, replace = FALSE)
  new_pop1 <- mix[select4pop1, ]
  new_pop2 <- mix[-select4pop1, ]
  list(pop1 = new_pop1, pop2 = new_pop2)
}
```

```{r}
calculatePVmulti <- function(pop, discrepancies, M_outer = 1000, M_inner) {
  # pop is a list whose two members are two sub-populations
  if (missing(M_inner))
    M_inner <- M_outer
  ## Local function to calculate the significance levels over the
  ## discrepancies and return their minimum
  getSLmin <- function(basePop, discrepancies, M) {
    observedVals <- sapply(discrepancies, FUN = function(discrepancy) {
      discrepancy(basePop)
    })
    K <- length(discrepancies)
    total <- Reduce(function(counts, i) {
      # mixRandomly mixes the two populations randomly, so the new
      # sub-populations are indistinguishable
      NewPop <- mixRandomly(basePop)
      ## calculate the discrepancy and counts
      Map(function(k) {
        Dk <- discrepancies[[k]](NewPop)
        if (Dk >= observedVals[k])
          counts[k] <<- counts[k] + 1
      }, 1:K)
      counts
    }, 1:M, init = numeric(length = K))
    SLs <- total/M
    min(SLs)
  }
  SLmin <- getSLmin(pop, discrepancies, M_inner)
  total <- Reduce(function(count, m) {
    basePop <- mixRandomly(pop)
    if (getSLmin(basePop, discrepancies, M_inner) <= SLmin)
      count + 1 else count
  }, 1:M_outer, init = 0)
  SLstar <- total/M_outer
  SLstar
}
```

\newpage

```{r}
bootstrap_t_interval_new <- function(S, a, confidence, B, D, ...) {
  ##    S = an n row data frame containing the variate values in the sample 
  ##    a = a scalar-valued function that calculates the attribute a() of interest 
  ##    confidence = a value in (0,1) indicating the confidence level 
  ##    B = a numeric value representing the outer bootstrap count of
  ##    replicates (used to calculate the lower and upper limits) 
  ##    D = a numeric value representing the inner bootstrap count of replicates
  ##    (used to estimate the standard deviation of the sample attribute for
  ##    each (outer) bootstrap sample)
  aS <- a(S)
  sampleSize <- nrow(S)
  ## get (outer) bootstrap values
  bVals <- sapply(1:B, FUN = function(b) {
    Sstar.idx <- sample(1:sampleSize, sampleSize, replace = TRUE)
    aSstar <- a(S[Sstar.idx,])
    ## get (inner) bootstrap values to estimate the SD
    SD_aSstar <- sd(sapply(1:D, FUN = function(d) {
      Sstarstar.idx <- sample(Sstar.idx, sampleSize, replace = TRUE)
      ## return the attribute value
      a(S[Sstarstar.idx,])
    }))
    z <- (aSstar - aS)/SD_aSstar
    ## Return the two values
    c(aSstar = aSstar, z = z)
  })
  SDhat <- sd(bVals["aSstar", ])
  zVals <- bVals["z", ]
  ## Now use these zVals to get the lower and upper c values.
  cValues <- quantile(zVals, probs = c((1 - confidence)/2, (confidence + 
                                                              1)/2), na.rm = TRUE)
  cLower <- min(cValues)
  cUpper <- max(cValues)
  interval <- c(lower = aS - cUpper * SDhat, middle = aS, upper = aS - 
                  cLower * SDhat)
  return(interval)
}
```
